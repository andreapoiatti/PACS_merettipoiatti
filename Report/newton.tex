\documentclass[a4paper,11 pt]{report}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage[toc,page]{appendix}
\usepackage{epstopdf}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{latexsym}
\usepackage[export] {adjustbox}
% package formato

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,stackengine}
\setlength{\topmargin}{0.0in}
\setlength{\headheight}{0.2in}
\setlength{\headsep}{0.0in}
% \setlength{\footheight}{0.0in}
\setlength{\footskip}{1in}
\setlength{\textheight}{8.3in}
\setlength{\textwidth}{6.0in}
\setlength{\oddsidemargin}{0.4in}
\setlength{\evensidemargin}{0.4in}
\setlength{\parindent}{0.4 in}
\usepackage{amsmath,amssymb}
\linespread{1.5}\selectfont
\setlength{\abovecaptionskip}{1pt} 



\usepackage{listings}
\usepackage{color}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows}
\tikzstyle{startstop} = [rectangle, rounded corners, minimum width=3cm, minimum height=1cm,text centered, draw=black, fill=red!30]
\tikzstyle{io} = [trapezium, trapezium left angle=70, trapezium right angle=110, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=blue!30]
\tikzstyle{process} = [rectangle, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=orange!30, text width=9.5cm]
\tikzstyle{process2} = [rectangle, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=orange!30]
\tikzstyle{decision} = [diamond, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=green!30]
\tikzstyle{arrow} = [thick,->,>=stealth]

\lstset{frame=tb,
	language=C++,
	aboveskip=3mm,
	belowskip=3mm,
	showstringspaces=false,
	columns=flexible,
	basicstyle={\small\ttfamily},
	numbers=none,
	numberstyle=\tiny\color{gray},
	keywordstyle=\color{blue},
	commentstyle=\color{dkgreen},
	stringstyle=\color{mauve},
	breaklines=true,
	breakatwhitespace=true,
	tabsize=3
}


\newcommand{\numberset}{\mathbb}
\newcommand{\N}{\numberset{N}}
\newcommand{\R}{\numberset{R}}
\usepackage{amsthm}

\theoremstyle{plain} 
\newtheorem{thm}{Theorem}[section] 
\newtheorem{cor}[thm]{Corollary} 
\newtheorem{lem}[thm]{Lemma} 
\newtheorem{prop}[thm]{Proposition} 

\theoremstyle{definition} 
\newtheorem{defn}{Definition}[chapter] 

\theoremstyle{remark} 
\newtheorem{oss}{Remark} 
\begin{document}
\section{The Newton's method}
In order to find the optimal value of the GCV function we chose to exploit Newton's method: in particular we need to find the root of the derivative of the function. As we can see in Figure, in general the GCV function has a particular shape which guarantees a single minimum, thus finding the zero of the derivative of the function seems to be the right choice.
Let $f: \R\rightarrow R$ a generic function, which could be the GCV function or another one, supposed to be sufficiently regular (at least $C^3(\R)$), and let $\alpha\in \R$ the single zero, such that $f''(\alpha)\neq 0$ (notice that the GCV in general respects this hypothesis, bacuase $f''(\alpha)>0$, since it is convex in a neighborhood of the minimizer $\alpha$). Then Newton method reads (see \cite{QSS}): 

up to convergence, fixed an initial guess $x_0$, for every $n>0$ compute
\begin{equation*}
x_{n+1}=x_n-\dfrac{f'(x_n)}{f''(x_n)}
\end{equation*}
where $f'$ and $f''$ are respectively the first and second derivatives if $f$.
As stopping criterion we compute the residual and compared with $TOL=5e-2$, stopping the iterations if
\begin{equation*}
|f'(x_n)|\leq TOL
\end{equation*}

The Newton's method has a quadratic order of convergence (if the initial guess is sufficiently close to the real root) to the zero $\alpha$, meaning that
\begin{equation*}
|x_{n+1}-\alpha|\leq C|x_n-\alpha|^2\ \ \ \ \forall n\geq 0
\end{equation*}
As we can see, Newton's method is computationally demanding, because we need to compute both the first and the second derivatives of the GCV function, which is highly inefficient due to the solution of very big linear systems involved in the computation. 

Then, we decided to propose another method, derived from the one just presented and then compared in efficiency with it. In particular, we substitute the exact derivatives with approximated derivatives computed by means of centered finite differences (see again \cite{QSS}), namely we approximate them in the following way, having set $h=4e-6$:
\begin{equation}
f'(x)\approx \dfrac{f(x+h)-f(x-h)}{2h}=:f'_{CD}(x)
\label{fd}
\end{equation}
and
\begin{equation}
f''(x)\approx \dfrac{f(x+h)-2f(x)+f(x-h)}{h^2}=:f''_{CD}(x)
\end{equation}
we know, by Taylor expansion with Lagrange form of the remainder, that 
\begin{equation}
f'(x)=f'_{CD}(x)+\mathcal{O}(h^2)
\label{fd2}
\end{equation}
and
\begin{equation}
f''(x)= f''_{CD}(x)+\mathcal{O}(h^2)
\label{fdd}
\end{equation}

The method thus reads:

up to convergence, fixed an initial guess $x_0$, for every $n>0$ compute
\begin{equation}
x_{n+1}=x_n-\frac{h}{2}\ \dfrac{f(x_n+h)-f(x_n-h)}{f(x_n+h)-2f(x_n)+f(x_n-h)}
\label{newt2}
\end{equation}
The underlying idea of the method can be explained with the following two-step procedure: 
\subsection*{Step 1}
We approximate $f'$ with $f'_{CD}$ defined in (\ref{fd}) and look for the zero of $f'_{CD}$. Indeed, if $\tilde{\alpha}$ is a zero of $f'_{CD}$, then 
\begin{equation*}
|f'(\tilde{\alpha})|= |f'(\tilde{\alpha})-f'_{CD}(\tilde{\alpha})|=\mathcal{O}(h^2),
\end{equation*} 
meaning that if we chose $h$ small enough, we can say that $f(\tilde{\alpha})$ is a good approximation of the minimum value of the function $f$, being the derivative $f'(\tilde{\alpha})$ very small in modulus. 
We are then led to find the root $\tilde{\alpha}$ of $f'_{CD}$.
\subsection*{Step 2}
The Newton's method applied to $f'_{CD}$ should read:


up to convergence, fixed an initial guess $x_0$, for every $n>0$ compute
\begin{equation}
x_{n+1}=x_n-\dfrac{f'_{CD}(x_n)}{\frac{d}{dx}f'_{CD}(x_n)}
\label{newt}
\end{equation}
but we recall that, due to (\ref{fd2}), we have also
\begin{equation}
f''(x)=\frac{d}{dx}f'_{CD}(x)+\mathcal{O}(h^2)
\label{eq}
\end{equation}
which implies, together with (\ref{fdd}):
\begin{equation}
\frac{d}{dx}f'_{CD}(x)=f''_{CD}(x)+\mathcal{O}(h^2)
\label{last}
\end{equation} 
substituting (\ref{last}) in (\ref{newt}), we obtain the following method, which is exactly the method (\ref{newt2}):
up to convergence, fixed an initial guess $x_0$, for every $n>0$ compute
\begin{equation}
x_{n+1}=x_n-\dfrac{f'_{CD}(x_n)}{f''_{CD}(x_n)}
\label{newt3}
\end{equation}
This method is still convergent (if the initial guess is sufficiently close to the real root) in the case of GCV function, indeed if we define 
$\Phi(x)=x-\dfrac{f'_{CD}(x)}{f''_{CD}(x)}$ we deduce that this method is a fixed point one and that, for $h$ sufficiently small, we have $|\Phi'(\tilde{\alpha})|<1$ and thus, as shown in (\cite{QSS}), the method is convergent and $x_n\rightarrow\tilde{\alpha}$. 


In the case of the GCV function, we know by the geometrical shape of the function that $f''(x)>0$ in a neighborood of the minimizer: therefore by the theorem of permanence of sign in the limit, we deduce $\frac{d}{dx}f'_{CD}(\tilde{\alpha})>0$ for $h$ small enough, concluding that $\Phi'(\tilde{\alpha})<1$.

Moreover, by equation (\ref{eq}), we get 
\begin{equation}
\Phi'(\tilde{\alpha})=1-\dfrac{\frac{d}{dx}f'_{CD}(\tilde{\alpha})}{\frac{d}{dx}f'_{CD}(\tilde{\alpha})+\mathcal{O}(h^2)}
\end{equation}
thus, for $h$ small enough, since for the GCV function $\frac{d}{dx}f'_{CD}(\tilde{\alpha})>0$
\begin{equation*}
\frac{d}{dx}f'_{CD}(\tilde{\alpha})>-2\ \mathcal{O}(h^2)=\mathcal{O}(h^2)
\end{equation*}
and then $\Phi'(\tilde{\alpha})>-1$. 
 

To sum up, we have obtained that $|\Phi'(\tilde{\alpha})|<1$: the fixed point method is convergent.
In particular, as $h\rightarrow0$, we have that $|\Phi'(\tilde{\alpha})|\rightarrow0$, which implies that, if we properly choose $h$, we can reach a method almost of order of convergence 2, as the exact Newton's method is. 

Actually, due to the particular shape of the GCV function, we have found that in many cases the value of $\frac{d}{dx}f'_{CD}(\tilde{\alpha})$ is very big [METTERE ESMPIO NUMERICO], then the value of $h$ chosen is very small compared to it, and thus the effectiveness of the method is enforced.

As we have seen, from step 2 we obtain the convergence of the method to a root of $f'_{CD}$, which is from step 1 very close to the real root of $f'$, which is our target. 

dire che sotto quel valore di lambda sotto h non si scende + inizializzazione

\begin{thebibliography}{9}
	\addcontentsline{toc}{chapter}{Bibliography}
	
	
	\bibitem{QSS} Quarteroni, A., Sacco, R., Saleri, F., Gervasio, P., \textit{Matematica Numerica, $4^a$ Ed.}, Springer, Berlin Heidelberg, 2013.
	

\end{thebibliography} 	
\end{document}